{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This removes all diacritics from a str. It is heavy handed and will do it for any character, even those that are not Latin languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Résumé, Shaved: Resume\n",
      "Original: Piqué, Shaved: Pique\n",
      "Original: naïve, Shaved: naive\n",
      "Original: São Paulo, Shaved: Sao Paulo\n",
      "Original: Él Niño, Shaved: El Nino\n",
      "Original: Beyoncé, Shaved: Beyonce\n",
      "Original: café, Shaved: cafe\n",
      "Original: jalapeño, Shaved: jalapeno\n",
      "Original: façade, Shaved: facade\n",
      "Original: coördinate, Shaved: coordinate\n",
      "Original: à la carte, Shaved: a la carte\n",
      "Original: Pokémon, Shaved: Pokemon\n",
      "Original: Mëtàl Hëàd, Shaved: Metal Head\n",
      "Original: 🎉Celebration time!, Shaved: 🎉Celebration time!\n",
      "Original: Hello, 世界, Shaved: Hello, 世界\n",
      "Original: Καλημέρα κόσμε, Shaved: Καλημερα κοσμε\n",
      "Original: Привет мир, Shaved: Привет мир\n",
      "Original: السلام عليكم, Shaved: السلام عليكم\n"
     ]
    }
   ],
   "source": [
    "# A list of strings with diacritic marks and special characters\n",
    "strings = [\n",
    "    'Résumé',\n",
    "    'Piqué',\n",
    "    'naïve',\n",
    "    'São Paulo',\n",
    "    'Él Niño',\n",
    "    'Beyoncé',\n",
    "    'café',\n",
    "    'jalapeño',\n",
    "    'façade',\n",
    "    'coördinate',\n",
    "    'à la carte',\n",
    "    'Pokémon',\n",
    "    'Mëtàl Hëàd',\n",
    "    '🎉Celebration time!',\n",
    "    'Hello, 世界',\n",
    "    'Καλημέρα κόσμε',\n",
    "    'Привет мир',\n",
    "    'السلام عليكم',\n",
    "]\n",
    "\n",
    "# Apply the function to each string and print the result\n",
    "for s in strings:\n",
    "    print(f'Original: {s}, Shaved: {shave_marks(s)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a version that will only shave the marks off if it it a Latin character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shave_marks_latin(txt):\n",
    "    \"\"\"Remove all diacritic marks from Latin base characters\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    preserve = []\n",
    "\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue # ignore diacritic on Latin base char\n",
    "        preserve.append(c)\n",
    "        # if it isn't combining char, it's a new base char\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(preserve)\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Résumé, Shaved: Resume\n",
      "Original: Piqué, Shaved: Pique\n",
      "Original: naïve, Shaved: naive\n",
      "Original: São Paulo, Shaved: Sao Paulo\n",
      "Original: Él Niño, Shaved: El Nino\n",
      "Original: Beyoncé, Shaved: Beyonce\n",
      "Original: café, Shaved: cafe\n",
      "Original: jalapeño, Shaved: jalapeno\n",
      "Original: façade, Shaved: facade\n",
      "Original: coördinate, Shaved: coordinate\n",
      "Original: à la carte, Shaved: a la carte\n",
      "Original: Pokémon, Shaved: Pokemon\n",
      "Original: Mëtàl Hëàd, Shaved: Metal Head\n",
      "Original: 🎉Celebration time!, Shaved: 🎉Celebration time!\n",
      "Original: Hello, 世界, Shaved: Hello, 世界\n",
      "Original: Καλημέρα κόσμε, Shaved: Καλημερα κοσμε\n",
      "Original: Привет мир, Shaved: Привет мир\n",
      "Original: السلام عليكم, Shaved: السلام عليكم\n"
     ]
    }
   ],
   "source": [
    "# A list of strings with diacritic marks and special characters\n",
    "strings = [\n",
    "    'Résumé',\n",
    "    'Piqué',\n",
    "    'naïve',\n",
    "    'São Paulo',\n",
    "    'Él Niño',\n",
    "    'Beyoncé',\n",
    "    'café',\n",
    "    'jalapeño',\n",
    "    'façade',\n",
    "    'coördinate',\n",
    "    'à la carte',\n",
    "    'Pokémon',\n",
    "    'Mëtàl Hëàd',\n",
    "    '🎉Celebration time!',\n",
    "    'Hello, 世界',\n",
    "    'Καλημέρα κόσμε',\n",
    "    'Привет мир',\n",
    "    'السلام عليكم',\n",
    "]\n",
    "\n",
    "# Apply the function to each string and print the result\n",
    "for s in strings:\n",
    "    print(f'Original: {s}, Shaved: {shave_marks(s)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will remove characters that are common in Western texts, but are not ASCII characters, and replace them with ASCII characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_map = str.maketrans(\"\"\"‚ƒ„ˆ‹‘’“”•–—˜›\"\"\", \"\"\"'f\"^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({\n",
    "    '€': 'EUR',\n",
    "    '…': '...',\n",
    "    'Æ': 'AE',\n",
    "    'æ': 'ae',\n",
    "    'Œ': 'OE',\n",
    "    'œ': 'oe',\n",
    "    '™': '(TM)',\n",
    "    '‰': '<per mille>',\n",
    "    '†': '**',\n",
    "    '‡': '***',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"Replace Win1252 symbols with ASCII chars or sequences\"\"\"\n",
    "    return txt.translate(multi_map)\n",
    "\n",
    "def asciiize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt))\n",
    "    no_marks = no_marks.replace('ß', 'ss')\n",
    "    return unicodedata.normalize('NFKC', no_marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dewinized: \"Herr Voß: - ½ cup of OEtker(TM) caffè latte - bowl of açaí.\"\n",
      "ASCIIized: \"Herr Voss: - 1⁄2 cup of OEtker(TM) caffe latte - bowl of acai.\"\n"
     ]
    }
   ],
   "source": [
    "order = '“Herr Voß: • ½ cup of Œtker™ caffè latte • bowl of açaí.”'\n",
    "\n",
    "print(\"Dewinized:\", dewinize(order))\n",
    "\n",
    "print(\"ASCIIized:\", asciiize(order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a command line utility to find the UTF number and name of a character (especially emojis and weird chars): it is in cf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "START, END = ord(' '), sys.maxunicode + 1\n",
    "\n",
    "def find(*query_words, start=START, end=END):\n",
    "    query = {w.upper() for w in query_words}\n",
    "    for code in range(start, end):\n",
    "        char = chr(code)\n",
    "        name = unicodedata.name(char, None)\n",
    "        if name and query.issubset(name.split()):\n",
    "            print(f'U+{code:04x}\\t{char}\\t{name}')\n",
    "            \n",
    "def main(words):\n",
    "    if words:\n",
    "        find(*words)\n",
    "    else:\n",
    "        print('Please provide words to find')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
