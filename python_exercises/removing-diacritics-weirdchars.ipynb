{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This removes all diacritics from a str. It is heavy handed and will do it for any character, even those that are not Latin languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    shaved = ''.join(c for c in norm_txt if not unicodedata.combining(c))\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: RÃ©sumÃ©, Shaved: Resume\n",
      "Original: PiquÃ©, Shaved: Pique\n",
      "Original: naÃ¯ve, Shaved: naive\n",
      "Original: SÃ£o Paulo, Shaved: Sao Paulo\n",
      "Original: Ã‰l NiÃ±o, Shaved: El Nino\n",
      "Original: BeyoncÃ©, Shaved: Beyonce\n",
      "Original: cafÃ©, Shaved: cafe\n",
      "Original: jalapeÃ±o, Shaved: jalapeno\n",
      "Original: faÃ§ade, Shaved: facade\n",
      "Original: coÃ¶rdinate, Shaved: coordinate\n",
      "Original: Ã  la carte, Shaved: a la carte\n",
      "Original: PokÃ©mon, Shaved: Pokemon\n",
      "Original: MÃ«tÃ l HÃ«Ã d, Shaved: Metal Head\n",
      "Original: ğŸ‰Celebration time!, Shaved: ğŸ‰Celebration time!\n",
      "Original: Hello, ä¸–ç•Œ, Shaved: Hello, ä¸–ç•Œ\n",
      "Original: ÎšÎ±Î»Î·Î¼Î­ÏÎ± ÎºÏŒÏƒÎ¼Îµ, Shaved: ÎšÎ±Î»Î·Î¼ÎµÏÎ± ÎºÎ¿ÏƒÎ¼Îµ\n",
      "Original: ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€, Shaved: ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€\n",
      "Original: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…, Shaved: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…\n"
     ]
    }
   ],
   "source": [
    "# A list of strings with diacritic marks and special characters\n",
    "strings = [\n",
    "    'RÃ©sumÃ©',\n",
    "    'PiquÃ©',\n",
    "    'naÃ¯ve',\n",
    "    'SÃ£o Paulo',\n",
    "    'Ã‰l NiÃ±o',\n",
    "    'BeyoncÃ©',\n",
    "    'cafÃ©',\n",
    "    'jalapeÃ±o',\n",
    "    'faÃ§ade',\n",
    "    'coÃ¶rdinate',\n",
    "    'Ã  la carte',\n",
    "    'PokÃ©mon',\n",
    "    'MÃ«tÃ l HÃ«Ã d',\n",
    "    'ğŸ‰Celebration time!',\n",
    "    'Hello, ä¸–ç•Œ',\n",
    "    'ÎšÎ±Î»Î·Î¼Î­ÏÎ± ÎºÏŒÏƒÎ¼Îµ',\n",
    "    'ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€',\n",
    "    'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…',\n",
    "]\n",
    "\n",
    "# Apply the function to each string and print the result\n",
    "for s in strings:\n",
    "    print(f'Original: {s}, Shaved: {shave_marks(s)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a version that will only shave the marks off if it it a Latin character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shave_marks_latin(txt):\n",
    "    \"\"\"Remove all diacritic marks from Latin base characters\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)\n",
    "    latin_base = False\n",
    "    preserve = []\n",
    "\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:\n",
    "            continue # ignore diacritic on Latin base char\n",
    "        preserve.append(c)\n",
    "        # if it isn't combining char, it's a new base char\n",
    "        if not unicodedata.combining(c):\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(preserve)\n",
    "    return unicodedata.normalize('NFC', shaved)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: RÃ©sumÃ©, Shaved: Resume\n",
      "Original: PiquÃ©, Shaved: Pique\n",
      "Original: naÃ¯ve, Shaved: naive\n",
      "Original: SÃ£o Paulo, Shaved: Sao Paulo\n",
      "Original: Ã‰l NiÃ±o, Shaved: El Nino\n",
      "Original: BeyoncÃ©, Shaved: Beyonce\n",
      "Original: cafÃ©, Shaved: cafe\n",
      "Original: jalapeÃ±o, Shaved: jalapeno\n",
      "Original: faÃ§ade, Shaved: facade\n",
      "Original: coÃ¶rdinate, Shaved: coordinate\n",
      "Original: Ã  la carte, Shaved: a la carte\n",
      "Original: PokÃ©mon, Shaved: Pokemon\n",
      "Original: MÃ«tÃ l HÃ«Ã d, Shaved: Metal Head\n",
      "Original: ğŸ‰Celebration time!, Shaved: ğŸ‰Celebration time!\n",
      "Original: Hello, ä¸–ç•Œ, Shaved: Hello, ä¸–ç•Œ\n",
      "Original: ÎšÎ±Î»Î·Î¼Î­ÏÎ± ÎºÏŒÏƒÎ¼Îµ, Shaved: ÎšÎ±Î»Î·Î¼ÎµÏÎ± ÎºÎ¿ÏƒÎ¼Îµ\n",
      "Original: ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€, Shaved: ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€\n",
      "Original: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…, Shaved: Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…\n"
     ]
    }
   ],
   "source": [
    "# A list of strings with diacritic marks and special characters\n",
    "strings = [\n",
    "    'RÃ©sumÃ©',\n",
    "    'PiquÃ©',\n",
    "    'naÃ¯ve',\n",
    "    'SÃ£o Paulo',\n",
    "    'Ã‰l NiÃ±o',\n",
    "    'BeyoncÃ©',\n",
    "    'cafÃ©',\n",
    "    'jalapeÃ±o',\n",
    "    'faÃ§ade',\n",
    "    'coÃ¶rdinate',\n",
    "    'Ã  la carte',\n",
    "    'PokÃ©mon',\n",
    "    'MÃ«tÃ l HÃ«Ã d',\n",
    "    'ğŸ‰Celebration time!',\n",
    "    'Hello, ä¸–ç•Œ',\n",
    "    'ÎšÎ±Î»Î·Î¼Î­ÏÎ± ÎºÏŒÏƒÎ¼Îµ',\n",
    "    'ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€',\n",
    "    'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…',\n",
    "]\n",
    "\n",
    "# Apply the function to each string and print the result\n",
    "for s in strings:\n",
    "    print(f'Original: {s}, Shaved: {shave_marks(s)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will remove characters that are common in Western texts, but are not ASCII characters, and replace them with ASCII characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_map = str.maketrans(\"\"\"â€šÆ’â€Ë†â€¹â€˜â€™â€œâ€â€¢â€“â€”Ëœâ€º\"\"\", \"\"\"'f\"^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({\n",
    "    'â‚¬': 'EUR',\n",
    "    'â€¦': '...',\n",
    "    'Ã†': 'AE',\n",
    "    'Ã¦': 'ae',\n",
    "    'Å’': 'OE',\n",
    "    'Å“': 'oe',\n",
    "    'â„¢': '(TM)',\n",
    "    'â€°': '<per mille>',\n",
    "    'â€ ': '**',\n",
    "    'â€¡': '***',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"Replace Win1252 symbols with ASCII chars or sequences\"\"\"\n",
    "    return txt.translate(multi_map)\n",
    "\n",
    "def asciiize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt))\n",
    "    no_marks = no_marks.replace('ÃŸ', 'ss')\n",
    "    return unicodedata.normalize('NFKC', no_marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dewinized: \"Herr VoÃŸ: - Â½ cup of OEtker(TM) caffÃ¨ latte - bowl of aÃ§aÃ­.\"\n",
      "ASCIIized: \"Herr Voss: - 1â„2 cup of OEtker(TM) caffe latte - bowl of acai.\"\n"
     ]
    }
   ],
   "source": [
    "order = 'â€œHerr VoÃŸ: â€¢ Â½ cup of Å’tkerâ„¢ caffÃ¨ latte â€¢ bowl of aÃ§aÃ­.â€'\n",
    "\n",
    "print(\"Dewinized:\", dewinize(order))\n",
    "\n",
    "print(\"ASCIIized:\", asciiize(order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a command line utility to find the UTF number and name of a character (especially emojis and weird chars): it is in cf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import unicodedata\n",
    "\n",
    "START, END = ord(' '), sys.maxunicode + 1\n",
    "\n",
    "def find(*query_words, start=START, end=END):\n",
    "    query = {w.upper() for w in query_words}\n",
    "    for code in range(start, end):\n",
    "        char = chr(code)\n",
    "        name = unicodedata.name(char, None)\n",
    "        if name and query.issubset(name.split()):\n",
    "            print(f'U+{code:04x}\\t{char}\\t{name}')\n",
    "            \n",
    "def main(words):\n",
    "    if words:\n",
    "        find(*words)\n",
    "    else:\n",
    "        print('Please provide words to find')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
